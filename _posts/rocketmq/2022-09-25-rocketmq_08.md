---
layout: post
title: "RocketMQ原理-Broker基本介绍&存储原理"
date:   2022-09-25
tags: [RocketMQ]
comments: true
author: xy
# toc: true  # 这里加目录导致看到地方太小了
---

主要内容如下:

1. `RocketMQ` `Broker`的启动流程以及重要功能介绍

2. `RocketMQ` 消息存储以及队列索引

    2.1 数据文件件commitlog

    2.2 消费文件consumequeue

    2.3 索引文件 indexfile

3. 消息存储同步异步刷盘

4. 消息清理机制

### 1. `Broker`的启动流程

`Broker`的启动类和控制器分别为 `BrokerStartup`、`BrokerController`这个和`NameServer`类似。

启动类就是读取配置(server, 存储, client等), 然后构造controller启动:
```java
public class BrokerStartup{
public static void main(String[] args) {
    BrokerConfig brokerConfig = new BrokerConfig();
    NettyServerConfig nettyServerConfig = new NettyServerConfig();
    NettyClientConfig nettyClientConfig = new NettyClientConfig();
    MessageStoreConfig messageStoreConfig = new MessageStoreConfig();

    BrokerController controller = new BrokerController(config..);

    controller.start();}
```

BrokerController 作为中介者依赖了大量的组件，这里就不贴代码了，对其简单归类可分为如下几大类:

1. 配置对象：Broker、Netty、消息存储等配置(一般以json文件的方式存储在本地)

2. 网络组件：基于Netty的服务器和客户端、API调用等

3. 生产者组件：生产者管理组件

4. 消费者组件：消费者管理、拉取消息、消费偏移量管理等组件

5. 消息存储：消息本地存储组件


核心成员如下:

```java
public class BrokerController {
    private final BrokerConfig brokerConfig;
    private final NettyServerConfig nettyServerConfig;

    private final ConsumerOffsetManager consumerOffsetManager;
    private final ConsumerManager consumerManager;
    private final ProducerManager producerManager;
    private final Broker2Client broker2Client;
    private final ConsumerIdsChangeListener consumerIdsChangeListener;
    private final RebalanceLockManager rebalanceLockManager = new RebalanceLockManager();
    private final BrokerOuterAPI brokerOuterAPI;
    private MessageStore messageStore;
}
```

例如`offset`的管理就是基础配置(支持加载序列化为`json`文件等):

```java
public abstract class ConfigManager {
    public boolean load() {
        fileName = this.configFilePath();
        String jsonString = MixAll.file2String(fileName);
        this.decode(jsonString);
    }
   ...
}
public class ConsumerOffsetManager extends ConfigManager{
    ConcurrentMap<String/* topic@group */, ConcurrentMap<Integer, Long>> offsetTable =new..
    public long queryOffset(final String group, final String topic, final int queueId){...}
    public String encode(final boolean prettyFormat) {
        return RemotingSerializable.toJson(this, prettyFormat);
    }
}
```

`consumeManager`用户管理`consumer`, 当`consume`数量变化(新增减少超时), 通知其他`client`做`reblance`。

```java
public class ConsumerManager{
    private final ConcurrentMap<String/* Group */, ConsumerGroupInfo> consumerTable = new..;
    public void doChannelCloseEvent(String remoteAddr, Channel channel){
        // client 收到通知reblance
        this.consumerIdsChangeListener.handle(ConsumerGroupEvent.UNREGISTER, );
    }
    public boolean registerConsumer(String group){
        // client 收到通知reblance
        this.consumerIdsChangeListener.handle(ConsumerGroupEvent.CHANGE, group....);
    }
    public void unregisterConsumer(String group){
        // client 收到通知reblance
        this.consumerIdsChangeListener.handle(ConsumerGroupEvent.UNREGISTER, group);
    }
    public void scanNotActiveChannel() {  扫描client是否有超时
        auto itChannel = channelInfoTable.entrySet().iterator();
        while (itChannel.hasNext()) {
            if(timeout){
                RemotingUtil.closeChannel(clientChannelInfo.getChannel());
            }
        }
    }
}
```

`ProducerManager`管理`produce`逻辑类似(`produce`的信息可以提供给`mq admin`然后给管理后台提供接口获取`produce`信息)。

`/broker/processor`下主要是`broker`提供给`client`的`rpc`请求处理接口, `SendMessageProcessor`处理`produce`生产消息。下面看下broker创建topic的流程:

```java
public class AdminBrokerProcessor extends AsyncNettyRequestProcessor...{
   RemotingCommand processRequest(ChannelHandlerContext ctx, RemotingCommand request){
        switch (request.getCode()) {
            case RequestCode.UPDATE_AND_CREATE_TOPIC:  // rpc请求创建topic
                return this.updateAndCreateTopic(ctx, request);
            case RequestCode.DELETE_TOPIC_IN_BROKER:
                return this.deleteTopic(ctx, request);
          ....
   }
   // 这里要加锁
    synchronized RemotingCommand updateAndCreateTopic(ChannelHandlerContext ctx,
        RemotingCommand request){
        String topic = requestHeader.getTopic();

        if (!TopicValidator.validateTopic(topic, response)) {
            return response;
        }
      
        TopicConfig topicConfig = new TopicConfig(topic);
        topicConfig.setReadQueueNums(requestHeader.getReadQueueNums());
        topicConfig.setWriteQueueNums(requestHeader.getWriteQueueNums());
        // 更新缓存以及持久化topic信息
        brokerController.getTopicConfigManager().updateTopicConfig(topicConfig);
        // 通知nameserver更新topic和broker信息
        brokerController.registerIncrementBrokerData(topicConfig);

        response.setCode(ResponseCode.SUCCESS);
        return response;      
   }  
}
```

简单看下`TopicConfigManager`缓存更新以及持久化：

```java
public void updateTopicConfig(final TopicConfig topicConfig) {
    TopicConfig old = this.topicConfigTable.put(topicConfig.getTopicName(), topicConfig);
    if (old != null) {
        log.info("update topic config, old:[{}] new:[{}]", old, topicConfig);
    } else {
        log.info("create new topic [{}]", topicConfig);
    }
    this.persist();
}
```


### 2. `RocketMQ` 消息存储以及队列索引

`broker` 的文件存储目录大体如下:

   ![img](../images/rocketmq.assests/store_1.png)

1. `数据文件件commitlog`: 消息主体以及元数据的存储主体

2. `消费文件consumequeue`: 消息消费队列

3. `索引文件 indexfile`: 例如可以通过 key(订单id等) 或时间区间来查询消息。

生产者发送消息到 Broker 端，然后 Broker 端使同步或者异步的方式对消息刷盘持久化，保存到commitlog 文件中。

与此同时Broker 端的后台服务线程会不停地分发请求并异步构建 consumequeue（消费文件）和 indexfile（索引文件）。

##### 2.1 数据文件件commitlog

`RocketMQ` 的消息数据都会写到数据文件中， 我们称之为 `commitlog`。所有的消息都会顺序写入到文件，当文件写满了，会写入到下个文件。`RocketMQ` 采用的是混合型的存储结构，`Broker` 单个实例下所有的队列共用一个数据文件（`commitlog`）来存储。

所有的消息都会顺序写入数据文件件，当文件写满了，会写入下一个文件。

   ![img](../images/rocketmq.assests/store_2.png)

如上图所示，单个一文件默认 1G , 文件名长度为 20 位，左边补零，剩余为起始偏移量, 如:00000000000000000000 代表了第一个文件，起始偏移量为 0 ，文件大小为1 G = 1073741824。当第一个文件写满了，第二个文件为 00000000001073741824，起始偏移量为 1073741824，以此类推。

存储接口定义如下:

```java
public interface MessageStore{
    boolean load();
    PutMessageResult putMessage(final MessageExtBrokerInner msg);
    PutMessageResult putMessages(final MessageExtBatch messageExtBatch);
    long getMaxOffsetInQueue(final String topic, final int queueId);
    QueryMessageResult queryMessage(final String topic, final String key...);
   ....
}
```

默认的store(写入磁盘以及更新到savle节点)：

```java
public class DefaultMessageStore implements MessageStore {
    MessageStoreConfig messageStoreConfig;
    ConcurrentMap<String/* topic */, ConcurrentMap<Integer/* queueId */, ConsumeQueue>> consumeQueueTable;
    FlushConsumeQueueService flushConsumeQueueService;
    IndexService indexService;
    HAService haService;
   ....
}
```

消息格式如下:

   ![img](../images/rocketmq.assests/store_3.png)


消息是一条条顺序写入到文件，每条消息的格式是固定的。设计有三点优势：

1. 顺序写速度比随机写(同时写多个文件)快几百~上前倍(随机写磁盘IO寻道时间和盘片旋转时间非常耗时)。

2. 快速定位：消息是一条条写如到 commitlog 文件 ，写完成后，我们可以得到这条消息的物理偏移量。(每条消息的物理偏移量是唯一的， commitlog 文件名是递增的，可以根据消息的物理偏移量通过二分查找，定位消息位于那个文件中，并获取到消息实体数据。)

3. 通过消息 offsetMsgId 查询消息数据.由 Broker 服务端在写入消息时生成的(Broker 服务端 ip + port 8个字节, commitlog 物理偏移量 8个字节)

   ![img](../images/rocketmq.assests/store_4.png)

我们可以通过消息`offsetMsgId`，定位到Broker的 ip 地址 + 端⼝ ，传递物理偏移量参数 ，即可定位该消息实体数据。


##### 2.2 消费文件consumequeue

消费文件按照主题-队列来保存 ，这种方式特别适配发布订阅模型。`consumequeue`文件格式如下:

   ![img](../images/rocketmq.assests/store_5.png)

1. 消费文件按照主题存储，每个主题下有不同的队列，图中 my-mac-topic 有 16 个队列;

2. 每个队列目录下,存储 consumequeue文件，每个 consumequeue文件也是顺序写入，数据格式如下图:

   ![img](../images/rocketmq.assests/store_6.png)


##### 2.3 索引文件 indexfile

每个消息在业务层的唯一标识码要设置到 keys 字段，方便将来定位消息丢失问题。服务器会为每个消息创建索引（哈
希索引）, 可以通过 topic、key 来查询这条消息内容，以及消息被谁消费(消息的properties会写入)。例如

```
String orderId = "20220925asdaxxxxxxxx"; 
message.setKeys(orderId); 
```

   ![img](../images/rocketmq.assests/store_7.png)


索引目录如下图所以：

   ![img](../images/rocketmq.assests/store_8.png)

IndexFile 的文件件逻辑结构类似于 JDK 的 HashMap 的数组加链表结构(具体后面在分析)。

### 3. 消息存储同步异步刷盘

两种模式枚举定义如下:

```java
public enum FlushDiskType {
    SYNC_FLUSH,
    ASYNC_FLUSH
}
```

broker此变量在message store配置中, 默认是异步

```java
public class MessageStoreConfig {
   ...
    private FlushDiskType flushDiskType = FlushDiskType.ASYNC_FLUSH;
}
```

`CommitLog`根据配置执行同步或者异步刷盘

```java
public class CommitLog{
public PutMessageResult putMessages(final MessageExtBatch messageExtBatch){
...
    handleDiskFlush(result, putMessageResult, messageExtBatch);
    handleHA(result, putMessageResult, messageExtBatch);
    return putMessageResult;
}

public void handleDiskFlush(AppendMessageResult result...){
    if (FlushDiskType.SYNC_FLUSH == defaultMessageStore.getMessageStoreConfig().getFlushDiskType()){
    ...同步刷盘
    }
...

```

`异步刷盘方式`：在返回写成功状态时，消息可能只是被写入了内存的PAGECACHE，写操作的返回快，吞吐量大；当内存里的消息量积累到一定程度时，统一触发写磁盘操作，快速写入。

`优点`：性能高

`缺点`：Master宕机，磁盘损坏的情况下，会丢失少量的消息

`同步刷盘方式`：在返回应用写成功状态前，消息已经被写入磁盘。具体流程是，消息写入内存的PAGECACHE后，立刻通知刷盘线程刷盘，然后等待刷盘完成。

`优点`：消息不丢失

`缺点`：性能比异步的低

实际应用中，推荐把`Master`和`Slave`设置成`ASYNC_FLUSH`的异步刷盘方式，主从之间配置成`SYNC_MASTER`的同步复制方式，这样即使有一台机器出故障，仍然可以保证数据不丢。

### 4. 消息清理机制

Broker消息清理机制如下:
1. CommitLog文件过期(72小时)，且达到清理时间点(默认为04:00~05:00)，自动清理过期的CommitLog文件

2. CommitLog文件过期(72小时)，且CommitLog所在磁盘分区占用率已经达到过期清理警戒线(默认75%)，无论是否到达清理时间点都会自动清理过期文件

3. CommitLog所在磁盘分区占用率已经达到系统危险警戒线(默认90%)，Broker将拒绝消息写入

`ConsumeQueue清理机制`

1. 如果ConsumeQueue文件关联CommitLog都被清理，则清理此ConsumeQueue文件

`IndexFile清理机制`

1. 如果IndexFile所有索引单元关联CommitLog都被清理，则清理此IndexFile

### 参考

https://juejin.cn/post/7229799197096149049

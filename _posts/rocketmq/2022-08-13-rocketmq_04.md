---
layout: post
title: "RocketMQ原理-Consumer原理一(pull Message)"
date:   2022-08-13
tags: [RocketMQ]
comments: true
author: xy
# toc: true  # 这里加目录导致看到地方太小了
---

`RocketMQ` 中消费者有两种方式获得消息来消费：`Push模式`和`Pull模式`:

1. `Pull模式`：客户端不断请求服务端poll消息

2. `Push模式`：基于Pull模式只需要我们提供一个listener即可实现对消息的监听

`RocketMQ` 的消费逻辑挺复杂的, 因此会通过多篇文章来分析, 本文主要分析`Pull模式`消费的核心流程。主要内容如下:

1. `RocketMQ` `Consumer`基本介绍, 以及简单示例

2. `RocketMQ` `OffsetStore`的本地存储以及`broker`存储

3. `DefaultMQPullConsumer` 核心代码流程


### 1. `RocketMQ` `Consumer`基本介绍, 以及简单示例

`RocketMQ` 支持两种消息消费模式：`集群消费` 和`广播消费`。

`集群消费`：同一 Topic 下的一条消息只会被同一消费组中的一个消费者消费。

`广播消费`：当使用广播消费模式时，每条消息推送给集群内所有的消费者，保证消息至少被每个消费者消费一次(`一般可以用于各个节点缓存同步`)。

两种模式如下图所示:

![img](../images/rocketmq.assests/consumer_1.png)

![img](../images/rocketmq.assests/consumer_2.png)


consume的简单示例如下(省略了异常处理, reblance等这些):

```c++
void pullConsumeExample(){
  DefaultMQPullConsumer consumer("testGroup");
  consumer.setNamesrvAddr("127.0.0.1:9876");
  consumer.registerMessageQueueListener("testTopic", NULL);
  consumer.start();
  
  // 获取到topic的所有(broker-queue列表)
  std::vector<MQMessageQueue> mqs;
  consumer.fetchSubscribeMessageQueues("testTopic", mqs);
  auto iter = mqs.begin();
  for (; iter != mqs.end(); ++iter) {
    std::cout << "mq:" << (*iter).toString() << endl;
  }

  // 遍历所有的(broker-queue)
  for (auto iter = mqs.begin(); iter != mqs.end(); ++iter) {
    MQMessageQueue mq = (*iter);

    // 拉取订阅的消息
    PullResult result = consumer.pull(mq, "*", getMessageQueueOffset(mq), 32);
    if (result.pullStatus != BROKER_TIMEOUT) {
      putMessageQueueOffset(mq, result.nextBeginOffset);   // 更新消费位点
      PrintPullResult(&result);  // 打印消息
    } else {
      cout << "broker timeout occur" << endl;
    }
  }
}
```

拉取回来的信息(核心成员):

```java
public class PullResult {
    private final PullStatus pullStatus;   有数据,没数据, 没有匹配tag, 异常
    private final long nextBeginOffset;
    private final long minOffset;    最大最小offset
    private final long maxOffset;
    private List<MessageExt> msgFoundList;  // 消息列表
```

拉取逻辑核心简化为两步:

```java
public class DefaultMQPullConsumerImpl{
PullResult pullSyncImpl(MessageQueue mq, subscriptionData, offset, maxNums){
    // 实际拉取消息
    PullResult pullResult = this.pullAPIWrapper.pullKernelImpl(...);

    // 按照tag, 以及自定义的过滤, 过滤掉消息
    this.pullAPIWrapper.processPullResult(mq, pullResult, subscriptionData);
    // hook...
    return pullResult;
}
```

`PullAPIWrapper`对拉取的消息做了`tag`过滤以及`hook`等处理, 核心功能如下:

```java
public class PullAPIWrapper {
final MQClientInstance mQClientFactory; // 实际调用rpc请求
ConcurrentMap<MessageQueue, AtomicLong/* brokerId */> pullFromWhichNodeTable = new...;
private ArrayList<FilterMessageHook> filterMessageHookList; // 过滤处理消息

public PullResult processPullResult(...){
    this.updatePullFromWhichNode(mq, pullResultExt.getSuggestWhichBrokerId());
    ByteBuffer byteBuffer = ByteBuffer.wrap(pullResultExt.getMessageBinary());
    List<MessageExt> msgList = MessageDecoder.decodes(byteBuffer);
    for (MessageExt msg : msgList) {
        if (subscriptionData.getTagsSet().contains(msg.getTags())) {
            msgListFilterAgain.add(msg);
        }
    }
```

以上就是`pull consume`模式的简单逻辑。


### 2. `RocketMQ` `OffsetStore`的本地存储以及`broker`存储

首先看下`OffsetStore`的使用, 启动`consumer`的时候:

1. 广播模式的时候用本地文件存储

2. 集群模式存储在broker端

```java
public class DefaultMQPullConsumerImpl{
....
private OffsetStore offsetStore;
public synchronized void start(){ // consumer启动的时候
...
    switch (this.defaultMQPullConsumer.getMessageModel()) {
        case BROADCASTING: //
            this.offsetStore = new LocalFileOffsetStore(this.mQClientFactory...);
            break;
        case CLUSTERING:    // 
            this.offsetStore = new RemoteBrokerOffsetStore(this.mQClientFactory....);
    }
    this.offsetStore.load();
}
public long fetchConsumeOffset(MessageQueue mq, boolean fromStore) throws MQClientException {
    return this.offsetStore.readOffset(mq, ...);
}
public void updateConsumeOffsetToBroker(MessageQueue mq, offset...){
    this.offsetStore.updateConsumeOffsetToBroker(mq, offset, isOneway);
}
public void updateConsumeOffset(MessageQueue mq, long offset){
    this.offsetStore.updateOffset(mq, offset, false);
```

与此同时支持`offset`的增删改查。下面看下`OffsetStore`的两种模式接口, 基类接口定义如下:

```java
public interface OffsetStore {
void load();
void updateOffset(final MessageQueue mq, final long offset);
long readOffset(final MessageQueue mq);
void persistAll(final Set<MessageQueue> mqs);
void persist(final MessageQueue mq);
void removeOffset(MessageQueue mq);
}
```

本地文件的存储定义如下(核心就是读取文件缓存以及更新文件)

```java
public class LocalFileOffsetStore implements OffsetStore {
    private final MQClientInstance mQClientFactory;
    private final String groupName;
    private final String storePath = LOCAL_DIR+File.separator+getClientId()+.."offsets.json";
    private ConcurrentMap<MessageQueue, AtomicLong> offsetTable = new ..; 缓存
    // 读取文件转化为mpa
    public void load(){
        // read from file 
        OffsetSerializeWrapper offsetSerializeWrapper = this.readLocalOffset();
        offsetTable.putAll(offsetSerializeWrapper.getOffsetTable());
      ...
    }
}
```

数据格式是json, 例如:

"""
{"OffsetTable":{{"brokerName":"broker_a", "QueueId": 1," Topic":"broker1"}: 1,
{"brokerName":"broker_b", "QueueId": 2," Topic":"broker1" }:2, 
{"brokerName":"broker_c", "QueueId": 0, "Topic":"broker1" }:3 } }
"""

远程的加载就是读取`broker`的`offset`, 更新也是存储到`broker`：

```java
public class RemoteBrokerOffsetStore implements OffsetStore {
private final MQClientInstance mQClientFactory;
private ConcurrentMap<MessageQueue, AtomicLong> offsetTable = new ...;

public long readOffset(final MessageQueue mq, final ReadOffsetType type){
   long brokerOffset = this.fetchConsumeOffsetFromBroker(mq);
   AtomicLong offset = new AtomicLong(brokerOffset);
   this.updateOffset(mq, offset.get(), false);
   return brokerOffset;   
}
private long fetchConsumeOffsetFromBroker(MessageQueue mq){
   FindBrokerResult findBrokerResult = mQClientFactory.findBrokerAddressInAdmin(getBrokerName());     
   QueryConsumerOffsetRequestHeader requestHeader = new QueryConsumerOffsetRequestHeader();
   requestHeader.setTopic(mq.getTopic());
   requestHeader.setConsumerGroup(this.groupName);
   requestHeader.setQueueId(mq.getQueueId());
   return mQClientFactory.getMQClientAPIImpl().queryConsumerOffset(getBrokerAddr(), requestHeader...);          
}
}
```

### 3. `DefaultMQPullConsumer` 核心代码流程

`DefaultMQPullConsumer` 是最基础版的`pullconsume`, 已经被`Deprecated`, 原因在于需要使用者维持`offset`, 提交`offset`, 使用起来不方便。一般如果使用`pull`方式消费可以用`DefaultLitePullConsumer`(维持消费的`offset`并且可以自动提交`offset`)。简单示例如下(简化版):

```java
public static void example()throws Exception{
    DefaultLitePullConsumer litePullConsumer = new DefaultLitePullConsumer("test");
    litePullConsumer.setAutoCommit(false);
    litePullConsumer.start();
    List<MessageQueue> mqlist = litePullConsumer.fetchMessageQueues("TopicTest");
    
    litePullConsumer.assign(mqlist);    // 赋值broker队列
    litePullConsumer.seek(assignList.get(0), 10);  // 设置offset

    while (running) {
        List<MessageExt> messageExts = litePullConsumer.poll();
        System.out.printf("%s %n", messageExts);
        litePullConsumer.commitSync();
    }

    litePullConsumer.shutdown();
}
```

下面看下`DefaultLitePullConsumer`的`pull`实现原理(简化了`reblance`这些), 核心成员:


```java
public class DefaultLitePullConsumerImpl implements MQConsumerInner{
    protected MQClientInstance mQClientFactory;
    private PullAPIWrapper pullAPIWrapper;
    private OffsetStore offsetStore;

    private final BlockingQueue<ConsumeRequest> consumeRequestCache = new...;

    private final ConcurrentMap<MessageQueue, PullTaskImpl> taskTable =
            new ConcurrentHashMap<MessageQueue, PullTaskImpl>();
```

线程定期去拉取各个`queue`的`message`缓存到`consumeRequestCache`中。`Poll`的实现就是读取缓存的`message`队列:

```java
public synchronized List<MessageExt> poll(long timeout){
    if (defaultLitePullConsumer.isAutoCommit()) {
        maybeAutoCommit();  // 自动提交位点
    }
    ConsumeRequest consumeRequest = consumeRequestCache.poll(...);
    while (consumeRequest != null && consumeRequest.getProcessQueue().isDropped()){
        consumeRequest = consumeRequestCache.poll(..);
    }
    if (consumeRequest != null && !consumeRequest.getProcessQueue().isDropped()){
        List<MessageExt> messages = consumeRequest.getMessageExts();
        long offset = consumeRequest.getProcessQueue().removeMessage(messages);
        assignedMessageQueue.updateConsumeOffset(consumeRequest.getMessageQueue(), offset);
        return messages;
    }
}
```

当`topic`的队列发送变化的时候定时线程会去定期更新拉取队列:

```java
private void updatePullTask(String topic, Set<MessageQueue> mqNewSet){
...
    startPullTask(mqNewSet);
}
private void startPullTask(Collection<MessageQueue> mqSet) {
    for (MessageQueue messageQueue : mqSet) {
        if (!this.taskTable.containsKey(messageQueue)) {
            PullTaskImpl pullTask = new PullTaskImpl(messageQueue);
            this.taskTable.put(messageQueue, pullTask);
            this.scheduledThreadPoolExecutor.schedule(pullTask, 0, ...);
```

拉取线程会做流控等策略, 防止队列数据太多, 消费不过来:

```java
public class PullTaskImpl implements Runnable {
    private final MessageQueue messageQueue;
    private volatile boolean cancelled = false;
    @Override
    public void run() {
        if (!this.isCancelled()) {
            ...
            if (consumeRequestCache.size() * getPullBatchSize() > getPullThresholdForAll()){
                // 延时流控
                scheduledThreadPoolExecutor.schedule(this, PULL_TIME_DELAY_FLOW_CONTROL, ...);
                return;
            }
            if(memoryBit > getMemory()){
                // 内存控制
                scheduledThreadPoolExecutor.schedule(this, PULL_TIME_DELAY_FLOW_CONTROL, ...);
                return;
            }

            PullResult pullResult = pull(messageQueue);
            processQueue.putMessage(pullResult.getMsgFoundList());
        }
    }
}
```

最后定时全部提交消费位点:

```java
private void maybeAutoCommit() {
    long now = System.currentTimeMillis();
    if (now >= nextAutoCommitDeadline) {
        commitAll();
        nextAutoCommitDeadline = now + defaultLitePullConsumer.getAutoCommitIntervalMillis();
    }
}
```

以上就是`pullconsume`的核心代码流程。
